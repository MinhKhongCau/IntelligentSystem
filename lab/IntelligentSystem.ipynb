{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNlHGN7IymoIuk3hIgR9eJ6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Training Facenet-v1 model"],"metadata":{"id":"1yuYaoYMNsht"}},{"cell_type":"markdown","source":["##Verify Nvidia\n","\n","Verify Nvidia for use GPU."],"metadata":{"id":"eVrdCUzYw1Ia"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFdE-MUsk-SL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758214700898,"user_tz":-420,"elapsed":138,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"28caeaec-f620-4aae-9dbf-05fda69148b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep 18 16:58:20 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   62C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","source":["Mount drive"],"metadata":{"id":"Tp_vRtPZ9BDg"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVdSy9RI3ux9","executionInfo":{"status":"ok","timestamp":1758217901875,"user_tz":-420,"elapsed":14456,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"d9683cb2-aaa0-4771-c085-b56a430214af"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"markdown","source":["## Preparing dataset\n","\n","This Python 3 environment comes with many helpful analytics libraries installed\n","\n","It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","\n","For example, here's several helpful packages to load\n"],"metadata":{"id":"XrhlJNy5yxSD"}},{"cell_type":"code","source":["\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"],"metadata":{"id":"VLNbtUuFyw-C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install kagglehub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCz1Vq2JzPkF","executionInfo":{"status":"ok","timestamp":1758215355088,"user_tz":-420,"elapsed":6520,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"8926e9bc-0839-4d43-dd96-22a9dc6e6d35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.8.3)\n"]}]},{"cell_type":"code","source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"quadeer15sh/celeba-face-recognition-triplets\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t13q-ci6zNiz","executionInfo":{"status":"ok","timestamp":1758215436085,"user_tz":-420,"elapsed":25483,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"e3fb1136-f23c-464e-cca3-38193d97cb7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/quadeer15sh/celeba-face-recognition-triplets?dataset_version_number=3...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231M/231M [00:11<00:00, 21.2MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/quadeer15sh/celeba-face-recognition-triplets/versions/3\n"]}]},{"cell_type":"markdown","source":["##Verify dataset"],"metadata":{"id":"kHFEMBk82wPm"}},{"cell_type":"code","source":["!ls /root/.cache/kagglehub/datasets/quadeer15sh/celeba-face-recognition-triplets/versions/3/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1odUDo22kZQ","executionInfo":{"status":"ok","timestamp":1758216411776,"user_tz":-420,"elapsed":115,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"4d334eaf-1bbc-4178-c488-53112c6b9425"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CelebAAttrs.csv  'CelebA FR Triplets'\n"]}]},{"cell_type":"code","source":["!ls /root/.cache/kagglehub/datasets/quadeer15sh/celeba-face-recognition-triplets/versions/3/CelebAAttrs.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kAFAkQWa0Ua-","executionInfo":{"status":"ok","timestamp":1758216359354,"user_tz":-420,"elapsed":118,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"6b2c0492-c92a-402d-c40c-c890c164096b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/.cache/kagglehub/datasets/quadeer15sh/celeba-face-recognition-triplets/versions/3/CelebAAttrs.csv\n"]}]},{"cell_type":"code","source":["!echo /root/.cache/kagglehub/datasets/quadeer15sh/celeba-face-recognition-triplets/versions/3/CelebA FR Triplets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vl49zthF2cYa","executionInfo":{"status":"ok","timestamp":1758216200642,"user_tz":-420,"elapsed":123,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"3e4107d5-68ea-47b0-9e76-322d87fe29e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/.cache/kagglehub/datasets/quadeer15sh/celeba-face-recognition-triplets/versions/3/CelebA FR Triplets\n"]}]},{"cell_type":"code","source":["for root, dirs, files in os.walk(\"/root/.cache/kagglehub/datasets/quadeer15sh/celeba-face-recognition-triplets/versions/3\"):\n","    for f in files[:10]:\n","        print(os.path.join(root, f))\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8CcnGTKn0ffm","executionInfo":{"status":"ok","timestamp":1758216011664,"user_tz":-420,"elapsed":37,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"58396bf8-76c6-4660-bb7d-d3006fad2a7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/.cache/kagglehub/datasets/quadeer15sh/celeba-face-recognition-triplets/versions/3/CelebAAttrs.csv\n"]}]},{"cell_type":"markdown","source":["Move to local drive"],"metadata":{"id":"culSbzNt8CPI"}},{"cell_type":"code","source":["!cp -r /root/.cache/kagglehub/datasets/quadeer15sh/celeba-face-recognition-triplets/versions/3 /content/drive/MyDrive/celeba_face_triplets"],"metadata":{"id":"dYTXTq3G3rML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, Dataset\n","import os\n","from torchvision import transforms\n","import pandas as pd\n","from PIL import Image\n","class TripletDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.image_dir = os.path.join(root_dir,'images')\n","        self.annotations = pd.read_csv(root_dir+'triplets.csv')\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.annotations.shape[0]\n","\n","    def __getitem__(self,index):\n","        anchor_img = self.annotations.iloc[index,0]\n","        positive_img = self.annotations.iloc[index,2]\n","        negative_img = self.annotations.iloc[index,4]\n","\n","        anc_img_path = os.path.join(self.image_dir, anchor_img)\n","        pos_img_path = os.path.join(self.image_dir, positive_img)\n","        neg_img_path = os.path.join(self.image_dir, negative_img)\n","\n","        anc_image = Image.open(anc_img_path).convert(\"RGB\")\n","        pos_image = Image.open(pos_img_path).convert(\"RGB\")\n","        neg_image = Image.open(neg_img_path).convert(\"RGB\")\n","\n","        if self.transform:\n","            anc_image = self.transform(anc_image)\n","            pos_image = self.transform(pos_image)\n","            neg_image = self.transform(neg_image)\n","        return anc_image, pos_image, neg_image"],"metadata":{"id":"e-VIR9wbzZxC","executionInfo":{"status":"ok","timestamp":1758217980453,"user_tz":-420,"elapsed":1601,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Subset\n","from sklearn.model_selection import train_test_split\n","path = '/content/drive/MyDrive/celeba_face_triplets/CelebA FR Triplets/CelebA FR Triplets/'\n","transform = transforms.Compose([\n","    transforms.Resize((112, 112)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","try:\n","    dataset = TripletDataset(root_dir=path, transform=transform)\n","    print(f\"Found {len(dataset)} triplets.\")\n","except Exception as e:\n","    print(f\"Could not load dataset. Error: {e}\")\n","\n","\n","train_indice, test_indice = train_test_split(list(range(len(dataset))),test_size=0.2, random_state=42)\n","train_subset, test_subset = Subset(dataset, train_indice), Subset(dataset, test_indice)\n","train_loader = DataLoader(train_subset, batch_size=32, shuffle=True,  num_workers=4,pin_memory=True, prefetch_factor=2)\n","test_loader = DataLoader(test_subset, batch_size=32, shuffle=True)\n","print(dataset[0][1].shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xtq3zWv_zgGy","executionInfo":{"status":"ok","timestamp":1758217982267,"user_tz":-420,"elapsed":99,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"ad8763b4-6e13-4a6f-b33f-6aecf93dc211"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 16332 triplets.\n","torch.Size([3, 112, 112])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","class FaceRecognition(nn.Module):\n","    def __init__(self):\n","        super(FaceRecognition,self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=8, kernel_size=3, padding=1) #112*112\n","        self.bn1 = nn.BatchNorm2d(8)\n","\n","        self.conv2 = nn.Conv2d(in_channels=8,out_channels=16, kernel_size=3, padding=1) #56*56\n","        self.bn2 = nn.BatchNorm2d(16)\n","\n","        self.conv3 = nn.Conv2d(in_channels=16,out_channels=32, kernel_size=3, padding=1) #28*28\n","        self.bn3 = nn.BatchNorm2d(32)\n","\n","        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1) #14*14\n","        self.bn4 = nn.BatchNorm2d(64)\n","\n","        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1) #7*7\n","        self.bn5 = nn.BatchNorm2d(128)\n","\n","        self.pool = nn.MaxPool2d(2,2)\n","\n","        self.fc1 = nn.Linear(in_features=128 * 3 * 3, out_features=512)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n","        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n","        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n","\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.normalize(x, p=2, dim=1)\n","\n","        return x\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"],"metadata":{"id":"XJH9TQvfzkXz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758218008287,"user_tz":-420,"elapsed":90,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"fd4c4152-9fe9-4ba3-8f4c-6f76275d6b5b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","from numpy.linalg import norm as norm\n","import torch.nn as nn\n","model = FaceRecognition().to(device)\n","# def triplet_loss():\n","#     alpha = 0.2 #A hyperparameter\n","#     loss = norm(anc_vec - pos_vec)-norm(anc_vec-neg_vec)+alpha\n","#     return loss\n","NUM_EPOCHS = 25\n","criterion = nn.TripletMarginLoss(margin=0.2, p=2)\n","optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader) * NUM_EPOCHS)"],"metadata":{"id":"aAKf9bdrzzib","executionInfo":{"status":"ok","timestamp":1758218121252,"user_tz":-420,"elapsed":194,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["NUM_EPOCHS = 25\n","model.train()\n","for epochs in range(NUM_EPOCHS):\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader):\n","        anc_images, pos_images, neg_images = data[0].to(device), data[1].to(device), data[2].to(device)\n","        anc_embedding = model(anc_images)\n","        pos_embedding = model(pos_images)\n","        neg_embedding = model(neg_images)\n","        optimizer.zero_grad()\n","\n","        loss = criterion(anc_embedding, pos_embedding, neg_embedding)\n","        loss.backward()\n","\n","        optimizer.step()\n","        scheduler.step()\n","\n","        running_loss += loss.item()\n","        if (i + 1) % 100 == 0:\n","            print(f'Epoch [{epochs + 1}/{NUM_EPOCHS}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')"],"metadata":{"id":"MXUlq5Lhz5XB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758221168187,"user_tz":-420,"elapsed":3040343,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"88eaf99c-a6bd-447e-bb32-c6a6ad1f203b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/25], Step [100/409], Loss: 0.1308\n","Epoch [1/25], Step [200/409], Loss: 0.1082\n","Epoch [1/25], Step [300/409], Loss: 0.0991\n","Epoch [1/25], Step [400/409], Loss: 0.0964\n","Epoch [2/25], Step [100/409], Loss: 0.0775\n","Epoch [2/25], Step [200/409], Loss: 0.0749\n","Epoch [2/25], Step [300/409], Loss: 0.0743\n","Epoch [2/25], Step [400/409], Loss: 0.0756\n","Epoch [3/25], Step [100/409], Loss: 0.0560\n","Epoch [3/25], Step [200/409], Loss: 0.0600\n","Epoch [3/25], Step [300/409], Loss: 0.0626\n","Epoch [3/25], Step [400/409], Loss: 0.0587\n","Epoch [4/25], Step [100/409], Loss: 0.0451\n","Epoch [4/25], Step [200/409], Loss: 0.0452\n","Epoch [4/25], Step [300/409], Loss: 0.0466\n","Epoch [4/25], Step [400/409], Loss: 0.0512\n","Epoch [5/25], Step [100/409], Loss: 0.0358\n","Epoch [5/25], Step [200/409], Loss: 0.0364\n","Epoch [5/25], Step [300/409], Loss: 0.0367\n","Epoch [5/25], Step [400/409], Loss: 0.0381\n","Epoch [6/25], Step [100/409], Loss: 0.0264\n","Epoch [6/25], Step [200/409], Loss: 0.0271\n","Epoch [6/25], Step [300/409], Loss: 0.0284\n","Epoch [6/25], Step [400/409], Loss: 0.0300\n","Epoch [7/25], Step [100/409], Loss: 0.0206\n","Epoch [7/25], Step [200/409], Loss: 0.0193\n","Epoch [7/25], Step [300/409], Loss: 0.0210\n","Epoch [7/25], Step [400/409], Loss: 0.0230\n","Epoch [8/25], Step [100/409], Loss: 0.0149\n","Epoch [8/25], Step [200/409], Loss: 0.0165\n","Epoch [8/25], Step [300/409], Loss: 0.0148\n","Epoch [8/25], Step [400/409], Loss: 0.0166\n","Epoch [9/25], Step [100/409], Loss: 0.0104\n","Epoch [9/25], Step [200/409], Loss: 0.0110\n","Epoch [9/25], Step [300/409], Loss: 0.0114\n","Epoch [9/25], Step [400/409], Loss: 0.0116\n","Epoch [10/25], Step [100/409], Loss: 0.0073\n","Epoch [10/25], Step [200/409], Loss: 0.0071\n","Epoch [10/25], Step [300/409], Loss: 0.0084\n","Epoch [10/25], Step [400/409], Loss: 0.0089\n","Epoch [11/25], Step [100/409], Loss: 0.0046\n","Epoch [11/25], Step [200/409], Loss: 0.0058\n","Epoch [11/25], Step [300/409], Loss: 0.0054\n","Epoch [11/25], Step [400/409], Loss: 0.0062\n","Epoch [12/25], Step [100/409], Loss: 0.0043\n","Epoch [12/25], Step [200/409], Loss: 0.0031\n","Epoch [12/25], Step [300/409], Loss: 0.0035\n","Epoch [12/25], Step [400/409], Loss: 0.0045\n","Epoch [13/25], Step [100/409], Loss: 0.0022\n","Epoch [13/25], Step [200/409], Loss: 0.0025\n","Epoch [13/25], Step [300/409], Loss: 0.0031\n","Epoch [13/25], Step [400/409], Loss: 0.0031\n","Epoch [14/25], Step [100/409], Loss: 0.0023\n","Epoch [14/25], Step [200/409], Loss: 0.0020\n","Epoch [14/25], Step [300/409], Loss: 0.0021\n","Epoch [14/25], Step [400/409], Loss: 0.0020\n","Epoch [15/25], Step [100/409], Loss: 0.0013\n","Epoch [15/25], Step [200/409], Loss: 0.0014\n","Epoch [15/25], Step [300/409], Loss: 0.0012\n","Epoch [15/25], Step [400/409], Loss: 0.0012\n","Epoch [16/25], Step [100/409], Loss: 0.0011\n","Epoch [16/25], Step [200/409], Loss: 0.0008\n","Epoch [16/25], Step [300/409], Loss: 0.0011\n","Epoch [16/25], Step [400/409], Loss: 0.0013\n","Epoch [17/25], Step [100/409], Loss: 0.0008\n","Epoch [17/25], Step [200/409], Loss: 0.0007\n","Epoch [17/25], Step [300/409], Loss: 0.0008\n","Epoch [17/25], Step [400/409], Loss: 0.0009\n","Epoch [18/25], Step [100/409], Loss: 0.0007\n","Epoch [18/25], Step [200/409], Loss: 0.0006\n","Epoch [18/25], Step [300/409], Loss: 0.0007\n","Epoch [18/25], Step [400/409], Loss: 0.0006\n","Epoch [19/25], Step [100/409], Loss: 0.0005\n","Epoch [19/25], Step [200/409], Loss: 0.0005\n","Epoch [19/25], Step [300/409], Loss: 0.0004\n","Epoch [19/25], Step [400/409], Loss: 0.0005\n","Epoch [20/25], Step [100/409], Loss: 0.0004\n","Epoch [20/25], Step [200/409], Loss: 0.0003\n","Epoch [20/25], Step [300/409], Loss: 0.0004\n","Epoch [20/25], Step [400/409], Loss: 0.0004\n","Epoch [21/25], Step [100/409], Loss: 0.0002\n","Epoch [21/25], Step [200/409], Loss: 0.0002\n","Epoch [21/25], Step [300/409], Loss: 0.0003\n","Epoch [21/25], Step [400/409], Loss: 0.0003\n","Epoch [22/25], Step [100/409], Loss: 0.0002\n","Epoch [22/25], Step [200/409], Loss: 0.0003\n","Epoch [22/25], Step [300/409], Loss: 0.0003\n","Epoch [22/25], Step [400/409], Loss: 0.0002\n","Epoch [23/25], Step [100/409], Loss: 0.0003\n","Epoch [23/25], Step [200/409], Loss: 0.0002\n","Epoch [23/25], Step [300/409], Loss: 0.0002\n","Epoch [23/25], Step [400/409], Loss: 0.0002\n","Epoch [24/25], Step [100/409], Loss: 0.0003\n","Epoch [24/25], Step [200/409], Loss: 0.0001\n","Epoch [24/25], Step [300/409], Loss: 0.0002\n","Epoch [24/25], Step [400/409], Loss: 0.0003\n","Epoch [25/25], Step [100/409], Loss: 0.0002\n","Epoch [25/25], Step [200/409], Loss: 0.0002\n","Epoch [25/25], Step [300/409], Loss: 0.0002\n","Epoch [25/25], Step [400/409], Loss: 0.0001\n","Finished Training\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/celeba_face_triplets/my_model_weights.pth')"],"metadata":{"id":"cvbpHLDzz96d","executionInfo":{"status":"ok","timestamp":1758221186332,"user_tz":-420,"elapsed":51,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","print(\"\\n--- Running Simple Evaluation on Test Set ---\")\n","\n","model.eval()\n","\n","total_loss = 0\n","correct_triplets = 0\n","total_triplets = 0\n","\n","with torch.no_grad():\n","    for data in test_loader:\n","        anc_images, pos_images, neg_images = data[0].to(device), data[1].to(device), data[2].to(device)\n","\n","        anc_embedding = model(anc_images)\n","        pos_embedding = model(pos_images)\n","        neg_embedding = model(neg_images)\n","\n","        loss = criterion(anc_embedding, pos_embedding, neg_embedding)\n","        total_loss += loss.item()\n","\n","        dist_pos = torch.norm(anc_embedding - pos_embedding, dim=1)\n","        dist_neg = torch.norm(anc_embedding - neg_embedding, dim=1)\n","\n","        correct_triplets += torch.sum(dist_pos < dist_neg).item()\n","        total_triplets += anc_images.size(0)\n","\n","\n","avg_test_loss = total_loss / len(test_loader)\n","accuracy = 100 * correct_triplets / total_triplets\n","\n","print(f\"Average Test Loss: {avg_test_loss:.4f}\")\n","print(f\"Triplet Accuracy: {accuracy:.2f}%\")\n"],"metadata":{"id":"lFjBktR50A2G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758221259612,"user_tz":-420,"elapsed":38398,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"1fd7a741-eb3e-4944-c8e8-403551273573"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Running Simple Evaluation on Test Set ---\n","Average Test Loss: 0.0727\n","Triplet Accuracy: 85.49%\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/celeba_face_triplets/my_model_weights.pth /content/drive/MyDrive/IntelligentSystem/my_model_weights.pth"],"metadata":{"id":"fYWJX7NlLQr2","executionInfo":{"status":"ok","timestamp":1758221693824,"user_tz":-420,"elapsed":111,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/IntelligentSystem"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aFxm0HAXOn7E","executionInfo":{"status":"ok","timestamp":1758222554132,"user_tz":-420,"elapsed":142,"user":{"displayName":"D22CQCN01-N NGO QUANG MINH","userId":"06129538004052187149"}},"outputId":"8996bdf2-68ba-4fa7-af20-cf8b790c74ca"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["IntelligentSystem.ipynb  my_model_weights.pth  TestModel.ipynb\n"]}]}]}